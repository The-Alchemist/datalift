# Datalift application configuration
#
# Set the "datalift.home" Java VM system property (or the "DATALIFT_HOME"
# environment variable to point at the root directory of the Datalift
# installation
#
# ============================================================================
#
# Local installation paths
#
# The directory where to look for DataLift modules
datalift.modules.path           = ${datalift.home}/modules
#
# The private and public file system storage paths
datalift.private.storage.path   = ${datalift.home}/storage
datalift.public.storage.path    = ${datalift.private.storage.path}/public
#
# ============================================================================
#
# The RDF repositories
#
# Two repository names are recognized and reserved:
#  - data:      the public (i.e. published) RDF data, and
#  - internal:  the DataLift internam data storage.
# All other names are available for module-specific repositories.
datalift.rdf.repositories       = data, internal
#
data.repository.url             = \
            http://localhost:8080/openrdf-sesame/repositories/lifted
data.repository.default         = true
#data.repository.username        = 
#data.repository.password        = 
#
internal.repository.url         = \
            http://localhost:8080/openrdf-sesame/repositories/internal
#internal.repository.username    = 
#internal.repository.password    = 
#
# Virtuoso repositories
#data.repository.url             = jdbc:virtuoso://localhost:1121
#data.repository.username        = dba
#data.repository.password        = dba
#data.repository.sparql.url      = http://localhost:8891/sparql
#
#internal.repository.url         = jdbc:virtuoso://localhost:1122
#internal.repository.username    = dba
#internal.repository.password    = dba
#internal.repository.sparql.url  = http://localhost:8892/sparql
#
# AllegroGraph repositories
#data.repository.url             = \
#        http://localhost:10035/catalogs/datalift/repositories/lifted
#data.repository.type            = allegrograph
#data.repository.username        = datalift
#data.repository.password        = test
#
#internal.repository.url         = \
#        http://localhost:10035/catalogs/datalift/repositories/internal
#internal.repository.type        = allegrograph
#internal.repository.username    = datalift
#internal.repository.password    = test
#
# ============================================================================
#
# SPARQL endpoint configuration
#
# The maximum duration of a SPARQL query, as a number of seconds.
# Any query taking longer to execute than this configured threshold
# will be aborted and partial results returned to the user.
# Default to -1 (no time limit).
#
#sparql.max.query.duration       = 30
#
# The predefined SPARQL queries definition file
# This RDF file (Turtle, N3, RDF/XML...) defines the predefined queries to
# make available on the SPARQL endpoint HTML user interface. Each query
# shall have <http://www.datalift.org/core#SparqlQuery> as RDF type, zero
# to N labels (<http://www.w3.org/2000/01/rdf-schema#label>) and the query
# string as RDF value (<http://www.w3.org/1999/02/22-rdf-syntax-ns#value>).
#
#sparql.predefined.queries.file  = ${datalift.home}/conf/predefined-queries.ttl
#
# ============================================================================
#
# Resource handling
#
# Whether to serve RDF resources before checking for files in public storage
# when resolving URIs.
# Defaults to false, i.e. files are checked and served first.
#
#datalift.resources.rdf.first    = false
#
# The duration (in seconds) the client is allowed to keep a representation in
# its local cache when a resource is accessed during business opening hours.
# Defaults to 2 hours (7200 seconds).
#
#datalift.cache.duration         = 7200
#
# The business opening hours. If a resource is accessed outside this range,
# the representation expiry date is the start of the next business day.
# The business day can cross the day boundary (e.g. 22:00-06:00) in case
# updates are being performed by nightly batches.
# Default to: 08:00-18:00.
#
#datalift.cache.businessDay      = 08:00-18:00
#
# ============================================================================
#
# Project manager configuration
#
# The license definition file
# This RDF file (Turtle, N3, RDF/XML...) defines the supported licenses for
# projects. Each definition shall have <http://www.datalift.org/core#License>
# as RDF type, a license URI (<http://purl.org/dc/terms/license>) and zero
# to N labels (<http://www.w3.org/2000/01/rdf-schema#label>).
#
#project.licenses.file           = ${datalift.home}/conf/licenses.ttl
#
# ============================================================================
#
# Security configuration
#
# Use simple properties file-based authentication for tests
propertiesRealm = org.apache.shiro.realm.text.PropertiesRealm
propertiesRealm.resourcePath = ${datalift.home}/conf/datalift-users.properties
#
